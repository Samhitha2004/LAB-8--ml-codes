{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba68baa4-d3fe-44ac-a661-5773bec211d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame:\n",
      "      age   income student credit_rating buys_computer\n",
      "0    <=30     high      no          fair            no\n",
      "1    <=30     high      no     excellent            no\n",
      "2   31…40     high      no          fair           yes\n",
      "3     >40   medium      no          fair           yes\n",
      "4     >40      low     yes          fair           yes\n",
      "5     >40      low     yes     excellent            no\n",
      "6   31…40      low     yes     excellent           yes\n",
      "7    <=30  medium       no          fair            no\n",
      "8    <=30      low     yes          fair           yes\n",
      "9     >40   medium     yes          fair           yes\n",
      "10   <=30   medium     yes     excellent           yes\n",
      "11  31…40   medium      no     excellent           yes\n",
      "12  31…40     high     yes          fair           yes\n",
      "13    >40   medium      no     excellent            no\n",
      "\n",
      "Prior Probabilities for age:\n",
      "age\n",
      "<=30     0.357143\n",
      ">40      0.357143\n",
      "31…40    0.285714\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Prior Probabilities for income:\n",
      "income\n",
      "medium     0.357143\n",
      "high       0.285714\n",
      "low        0.285714\n",
      "medium     0.071429\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Prior Probabilities for credit_rating:\n",
      "credit_rating\n",
      "fair         0.571429\n",
      "excellent    0.428571\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Prior Probabilities for buys_computer:\n",
      "buys_computer\n",
      "yes    0.642857\n",
      "no     0.357143\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Prior Probabilities for student:\n",
      "student\n",
      "no     0.5\n",
      "yes    0.5\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#A1\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming your Excel file is named 'your_dataset.xlsx'\n",
    "# Adjust the file path accordingly\n",
    "file_path = 'dataset-mllabage.xlsx'\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(\"Loaded DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Calculate prior probabilities for each class\n",
    "class_columns = ['age', 'income', 'credit_rating', 'buys_computer', 'student']\n",
    "\n",
    "for column in class_columns:\n",
    "    class_counts = df[column].value_counts()\n",
    "    total_instances = len(df)\n",
    "    \n",
    "    prior_probabilities = class_counts / total_instances\n",
    "\n",
    "    # Display the prior probabilities for the current class\n",
    "    print(f\"\\nPrior Probabilities for {column}:\")\n",
    "    print(prior_probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "daee81c9-a204-4a36-ba87-289e4ddb2e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame:\n",
      "      age   income student credit_rating buys_computer\n",
      "0    <=30     high      no          fair            no\n",
      "1    <=30     high      no     excellent            no\n",
      "2   31…40     high      no          fair           yes\n",
      "3     >40   medium      no          fair           yes\n",
      "4     >40      low     yes          fair           yes\n",
      "5     >40      low     yes     excellent            no\n",
      "6   31…40      low     yes     excellent           yes\n",
      "7    <=30  medium       no          fair            no\n",
      "8    <=30      low     yes          fair           yes\n",
      "9     >40   medium     yes          fair           yes\n",
      "10   <=30   medium     yes     excellent           yes\n",
      "11  31…40   medium      no     excellent           yes\n",
      "12  31…40     high     yes          fair           yes\n",
      "13    >40   medium      no     excellent            no\n",
      "\n",
      "Class Conditional Densities for age:\n",
      "Class: no\n",
      "age\n",
      "<=30    0.6\n",
      ">40     0.4\n",
      "Name: proportion, dtype: float64\n",
      "Class: yes\n",
      "age\n",
      "31…40    0.444444\n",
      ">40      0.333333\n",
      "<=30     0.222222\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class Conditional Densities for income:\n",
      "Class: no\n",
      "income\n",
      "high       0.4\n",
      "low        0.2\n",
      "medium     0.2\n",
      "medium     0.2\n",
      "Name: proportion, dtype: float64\n",
      "Class: yes\n",
      "income\n",
      "medium    0.444444\n",
      "low       0.333333\n",
      "high      0.222222\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class Conditional Densities for student:\n",
      "Class: no\n",
      "student\n",
      "no     0.8\n",
      "yes    0.2\n",
      "Name: proportion, dtype: float64\n",
      "Class: yes\n",
      "student\n",
      "yes    0.666667\n",
      "no     0.333333\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class Conditional Densities for credit_rating:\n",
      "Class: no\n",
      "credit_rating\n",
      "excellent    0.6\n",
      "fair         0.4\n",
      "Name: proportion, dtype: float64\n",
      "Class: yes\n",
      "credit_rating\n",
      "fair         0.666667\n",
      "excellent    0.333333\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#A2 \n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Adjust the file path to your Excel file\n",
    "file_path = 'dataset-mllabage.xlsx'\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(\"Loaded DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Define the class column\n",
    "class_column = 'buys_computer'\n",
    "\n",
    "# Define the features to calculate class conditional densities\n",
    "feature_columns = ['age', 'income', 'student', 'credit_rating']\n",
    "\n",
    "# Calculate class conditional densities\n",
    "for feature in feature_columns:\n",
    "    print(f\"\\nClass Conditional Densities for {feature}:\")\n",
    "    for class_label in df[class_column].unique():\n",
    "        class_data = df[df[class_column] == class_label][feature]\n",
    "\n",
    "        # For categorical features, calculate probability mass function (PMF)\n",
    "        if df[feature].dtype == 'O':\n",
    "            class_conditional_density = class_data.value_counts(normalize=True)\n",
    "        # For continuous features, assume Gaussian distribution and use PDF\n",
    "        else:\n",
    "            mean = class_data.astype(float).mean()\n",
    "            std_dev = class_data.astype(float).std()\n",
    "            class_conditional_density = norm.pdf(df[feature], mean, std_dev)\n",
    "\n",
    "        # Display the results\n",
    "        print(f\"Class: {class_label}\")\n",
    "        print(class_conditional_density)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89859fef-a309-4f3d-9471-fe66b9785a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame:\n",
      "      age   income student credit_rating buys_computer\n",
      "0    <=30     high      no          fair            no\n",
      "1    <=30     high      no     excellent            no\n",
      "2   31…40     high      no          fair           yes\n",
      "3     >40   medium      no          fair           yes\n",
      "4     >40      low     yes          fair           yes\n",
      "5     >40      low     yes     excellent            no\n",
      "6   31…40      low     yes     excellent           yes\n",
      "7    <=30  medium       no          fair            no\n",
      "8    <=30      low     yes          fair           yes\n",
      "9     >40   medium     yes          fair           yes\n",
      "10   <=30   medium     yes     excellent           yes\n",
      "11  31…40   medium      no     excellent           yes\n",
      "12  31…40     high     yes          fair           yes\n",
      "13    >40   medium      no     excellent            no\n",
      "\n",
      "Chi-square value: 15.749999999999998\n",
      "P-value: 0.6099899350400623\n",
      "\n",
      "Fail to reject the null hypothesis. There is no significant evidence of dependence between the variables.\n"
     ]
    }
   ],
   "source": [
    "#A3\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Assuming your Excel file is named 'dataset-mllabage.xlsx'\n",
    "# Adjust the file path accordingly\n",
    "file_path = 'dataset-mllabage.xlsx'\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(\"Loaded DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Define the observed frequency table\n",
    "observed_table = pd.crosstab(index=df['age'], columns=[df['income'], df['student'], df['credit_rating']])\n",
    "\n",
    "# Perform the Chi-square test of independence\n",
    "chi2, p, _, _ = chi2_contingency(observed_table)\n",
    "\n",
    "# Display the results\n",
    "print(f\"\\nChi-square value: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "\n",
    "# Set the significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Check for independence based on the p-value\n",
    "if p < alpha:\n",
    "    print(\"\\nReject the null hypothesis. There is evidence of dependence between the variables.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis. There is no significant evidence of dependence between the variables.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542e30d5-e30a-4ecd-ac0b-378ea7e1f63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chi-squared test for independence between 'age' and 'income':\n",
      "Chi-squared: 5.7749999999999995\n",
      "p-value: 0.44886095560958694\n",
      "\n",
      "Chi-squared test for independence between 'age' and 'student':\n",
      "Chi-squared: 0.4\n",
      "p-value: 0.8187307530779818\n",
      "\n",
      "Chi-squared test for independence between 'age' and 'credit_rating':\n",
      "Chi-squared: 0.11666666666666664\n",
      "p-value: 0.9433354498734922\n",
      "\n",
      "Chi-squared test for independence between 'income' and 'student':\n",
      "Chi-squared: 6.2\n",
      "p-value: 0.10227502654693751\n",
      "\n",
      "Chi-squared test for independence between 'income' and 'credit_rating':\n",
      "Chi-squared: 1.9541666666666668\n",
      "p-value: 0.5819738694716983\n",
      "\n",
      "Chi-squared test for independence between 'student' and 'credit_rating':\n",
      "Chi-squared: 0.0\n",
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "#A3\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import chi2_contingency, f_oneway\n",
    "\n",
    "df=pd.read_excel(\"dataset-mllabage.xlsx\")\n",
    " \n",
    "features = ['age', 'income', 'student', 'credit_rating']\n",
    " \n",
    "# Test for independence between all pairs of features\n",
    "\n",
    "for i in range(len(features)):\n",
    "\n",
    "    for j in range(i+1, len(features)):\n",
    "\n",
    "        feature1 = features[i]\n",
    "\n",
    "        feature2 = features[j]\n",
    " \n",
    "        # Categorical vs. Categorical (Chi-squared test)\n",
    "\n",
    "        if df[feature1].dtype == 'object' and df[feature2].dtype == 'object':\n",
    "\n",
    "            contingency_table = pd.crosstab(df[feature1], df[feature2])\n",
    "\n",
    "            chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "            print(f\"\\nChi-squared test for independence between '{feature1}' and '{feature2}':\")\n",
    "\n",
    "            print(\"Chi-squared:\", chi2)\n",
    "\n",
    "            print(\"p-value:\", p)\n",
    " \n",
    "        # Numeric vs. Categorical (ANOVA test)\n",
    "\n",
    "        elif df[feature1].dtype != 'object' and df[feature2].dtype == 'object':\n",
    "\n",
    "            for category in df[feature2].unique():\n",
    "\n",
    "                subset = df[df[feature2] == category]\n",
    "\n",
    "                f_stat, p_value = f_oneway(subset[feature1])\n",
    "\n",
    "                print(f\"\\nANOVA test for independence between '{feature1}' and '{feature2}={category}':\")\n",
    "\n",
    "                print(\"F-statistic:\", f_stat)\n",
    "\n",
    "                print(\"p-value:\", p_value)\n",
    " \n",
    "        # Numeric vs. Numeric (Pearson correlation coefficient)\n",
    "\n",
    "        elif df[feature1].dtype != 'object' and df[feature2].dtype != 'object':\n",
    "\n",
    "            correlation = df[feature1].corr(df[feature2])\n",
    "\n",
    "            print(f\"\\nPearson correlation coefficient between '{feature1}' and '{feature2}':\")\n",
    "\n",
    "            print(\"Correlation:\", correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f13c37e8-4e69-44ab-a6bd-53b97184ddf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of the Naive-Bayes classifier for the given dataset: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "#A4\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming your Excel file is named 'dataset-mllabage.xlsx'\n",
    "# Adjust the file path accordingly\n",
    "file_path = 'dataset-mllabage.xlsx'\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming 'buys_computer' is the target variable\n",
    "X = df[['age', 'income', 'student', 'credit_rating']]\n",
    "y = df['buys_computer']\n",
    "\n",
    "# Preprocess categorical features (convert to one-hot encoding)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "Tr_X, Te_X, Tr_y, Te_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Categorical Naive-Bayes classifier\n",
    "model = CategoricalNB()\n",
    "model.fit(Tr_X, Tr_y)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model.predict(Te_X)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(Te_y, predictions)\n",
    "print(f\"\\nAccuracy of the Naive-Bayes classifier for the given dataset: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b861f76e-abb5-4cdf-9bcd-deb58123a40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of the Naive-Bayes classifier: 0.035083160083160085\n"
     ]
    }
   ],
   "source": [
    "#A5\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load a subset of your dataset into a DataFrame\n",
    "# Adjust the file path accordingly\n",
    "file_path = 'mldatasetfinal numbers.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Replace 'target_variable' with the actual name of your target variable\n",
    "X = df.drop(['Price'], axis=1)\n",
    "y = df['Price']\n",
    "\n",
    "# Preprocess categorical features (convert to one-hot encoding)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Convert the DataFrame to a document-term matrix (DTM)\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "X_dtm = vectorizer.fit_transform(X.astype(str).apply(lambda x: ' '.join(x), axis=1))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "Tr_X, Te_X, Tr_y, Te_y = train_test_split(X_dtm, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Multinomial Naive-Bayes classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(Tr_X, Tr_y)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model.predict(Te_X)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(Te_y, predictions)\n",
    "print(f\"\\nAccuracy of the Naive-Bayes classifier: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
